{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.rochester.edu/assets/images/ur-logo.svg\">\n",
    "\n",
    "# <center>[CSC 249/449: Machine Vision](https://www.cs.rochester.edu/~cxu22/t/249S22/)</center>\n",
    "\n",
    "\n",
    "1. Make sure you fill in all cells contain `YOUR CODE HERE` or `YOUR ANSWER HERE`.\n",
    "2. After you finished, `Restart the kernel & run` all cell in order.\n",
    "---------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motion Estimation\n",
    "\n",
    "This project helps you get your hands on estimating pixel motion by solving **optical flow** problem. Given two consecutive frames with small motion, the machine should be able to estimate the motion by following **brightness constancy**.\n",
    "\n",
    "As discussed in the class, we can transform the problem of motion estimation into solving the equation with **brightness constancy** and **spatial coherence** constraints:\n",
    "\n",
    "$$\n",
    "\\nabla I(p_i) \\cdot [u,v] + I_t(p_i) = 0\n",
    "$$\n",
    "\n",
    "The number of equations per pixel is related to the selected window size. \n",
    "\n",
    "In this project, the overall pipeline is decomposed to two parts:\n",
    "\n",
    "1. **Compute Gradients**: You will need to get the image gradients along x, y, and also the time axes. You should be familiar with this since you have already experienced how to compute gradients in the previous problem set.\n",
    "2. **Flow Estimation**: Given the image gradients, you will solve the aperture problem to obtain the $[u,v]$ for pixels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import csc249\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read current frame and the next frame\n",
    "img_cur = cv2.cvtColor(cv2.imread(str(csc249.data/'basketball1.png')), cv2.COLOR_BGR2GRAY)\n",
    "img_next = cv2.cvtColor(cv2.imread(str(csc249.data/'basketball2.png')), cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "fig.add_subplot(1, 2, 1)\n",
    "plt.imshow(img_cur, cmap='gray')\n",
    "plt.title(\"Current Img\")\n",
    "fig.add_subplot(1, 2, 2)\n",
    "plt.imshow(img_next, cmap='gray')\n",
    "plt.title(\"Next Img\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Compute Gradients\n",
    "\n",
    "Recall the steps of image filtering and gradients:\n",
    "\n",
    "1. Generate image filters along $x$, $y$, and $time$ axes, respectively.(3 points)\n",
    "2. Apply the filters on images to get the gradients(7 points)\n",
    "    * The filters X, Y should be applied on the current image, while the gradients should be computed from both the current and the next image\n",
    "    * Use `cv2.filter2D` to implement the filtering    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5852d2485e3fa9a47110d793ca44dfa7",
     "grade": true,
     "grade_id": "cell-635cb8cded842add",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# return X,Y,T filters\n",
    "def firstorder():\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "    --------\n",
    "        filter X: numpy.ndarray\n",
    "        filter Y: numpy.ndarray  \n",
    "        filter T: numpy.ndarray\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    X = [-1, 1]\n",
    "    Y = [[-1], [1]]\n",
    "    T = [1]\n",
    "    #raise NotImplementedError()\n",
    "    return {'filterX': X,\n",
    "            'filterY':Y, \n",
    "            'filterT': T}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If correctly implemented, you should get three filters that will be passed into the next function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "019a214922b32cd605a4235ef74e8c9d",
     "grade": true,
     "grade_id": "cell-fa2d63cb7646db04",
     "locked": false,
     "points": 7,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# compute gradients on images\n",
    "def get_gradient(img_cur, img_next, filters):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    ----------\n",
    "        img_cur, img_next : the current and the next grayscale images\n",
    "            A 2D numpy.ndarray of shape H x W.\n",
    "        filters: filters\n",
    "            a dictonary of numpy.ndarray\n",
    "    Returns:\n",
    "    --------\n",
    "        grad_x, grad_y, grad_t: numpy.ndarray\n",
    "            H x W array of gradients in image coordinates\n",
    "    \"\"\"\n",
    "    X = filters['filterX']\n",
    "    Y = filters['filterY']\n",
    "    T = filters['filterT']\n",
    "    # YOUR CODE HERE\n",
    "    gx = cv2.filter2D(img_cur, -1, np.array(X))\n",
    "    gy = cv2.filter2D(img_cur, -1, np.array(Y))\n",
    "    gtcur = cv2.filter2D(img_cur, -1, np.array(T))\n",
    "    gtnext = cv2.filter2D(img_next, -1, np.ndarray(T))\n",
    "    gt = gtnext - gtcur\n",
    "    #raise NotImplementedError()\n",
    "    return {'grad_x': gx, \n",
    "            'grad_y': gy, \n",
    "            'grad_t': gt}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flow Estimation(15 points)\n",
    "\n",
    "Refer to the class, solving the aperture problem can help get the pixel movement $[u,v]$. Other than estimating motion on all the pixels, we first detect a set of good feature points. In this case, you are actually iterating the flow estimation on the selected points. The function involves the following steps:\n",
    "\n",
    "1. Unpack the [x,y] coordinates from the detected corners\n",
    "    * The return coordinates are in [y,x] format\n",
    "2. Compute the $I_x$, $I_y$ and $I_t$ for each neighbors inside the window\n",
    "    * The $I_x$, $I_y$ and $I_t$ may be in 2D shape, you can use `.flatten()` to make them into 1D arrays\n",
    "3. If you use 5x5 for the windows, now you will have 25 equations to compute the $(u,v)$ for each pixel. The overall equation is $A$$d$ = $b$ (the same as in class materials). Then you can get this $(u,v)$ by solving least squares problem\n",
    "    * Hint: use `np.linalg.pinv()` function to get the matrix that solves the least-squares problem\n",
    "4. After running over all the detected points, return the updated flow\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ded8f6e5201c6acfe5f8862b27bab29f",
     "grade": true,
     "grade_id": "cell-3694c7955ddf15a4",
     "locked": false,
     "points": 15,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def solving_aperture(flow, corners, grads, window_size):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    ----------\n",
    "        flow: the initial flow with all pixels of zero values\n",
    "            Two 2D numpy.ndarray [u, v] of shape H x W.\n",
    "        corners: the detected strong corners on image\n",
    "            a list of [y, x] coordinates\n",
    "        grads: the image gradients\n",
    "        window_size: the number of neighbors/equations to compute [u,v] \n",
    "    Returns:\n",
    "    --------\n",
    "        u, v: numpy.ndarray\n",
    "            two H x W arrays representing the flow\n",
    "    \"\"\"\n",
    "    # extract gradients\n",
    "    gx = grads['grad_x']\n",
    "    gy = grads['grad_y']\n",
    "    gt = grads['grad_t']\n",
    "    \n",
    "    # extract u, v\n",
    "    u = flow['u']\n",
    "    v = flow['v']\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    # We first pad the gradients to ensure that no out-of-bound error occurs.\n",
    "    # We then compute u, v at each of the strong corners detected using the formula in the lecture.\n",
    "    m = window_size // 2\n",
    "    Gx = np.pad(gx, pad_width = m)\n",
    "    Gy = np.pad(gy, pad_width = m)\n",
    "    Gt = np.pad(gt, pad_width = m)\n",
    "    for coor in corners:\n",
    "        x = coor[1]\n",
    "        y = coor[0]\n",
    "        A = []\n",
    "        b = []\n",
    "        for i in range(window_size):\n",
    "            for j in range(window_size):\n",
    "                A.append([Gx[x + i][y + j], Gy[x + i][y + j]])\n",
    "                b.append(-Gt[x + i][y + j])\n",
    "        A = np.array(A)\n",
    "        b = np.array(b)\n",
    "        b = np.transpose(b)\n",
    "        d = np.matmul(np.linalg.pinv(A), b)\n",
    "        u[x][y] = d.item(1)\n",
    "        v[x][y] = d.item(0)\n",
    "    #raise NotImplementedError()\n",
    "    return {'u':u,\n",
    "           'v':v}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you got it right so far, you should be able to get your flow visualization similar to this:\n",
    "\n",
    "![alt text](result.png \"Flow Result Example\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_corners=10000\n",
    "min_quality=0.01\n",
    "min_distance=0.1\n",
    "corners = cv2.goodFeaturesToTrack(img_cur, max_corners, min_quality, min_distance)\n",
    "corners = np.squeeze(corners).astype(int)\n",
    "\n",
    "img_cur = img_cur / 255\n",
    "img_next = img_next / 255\n",
    "\n",
    "filters = firstorder()\n",
    "\n",
    "grads = get_gradient(img_cur, img_next, filters)\n",
    "\n",
    "# initialize the flow\n",
    "u = np.zeros(img_cur.shape)\n",
    "v = np.zeros(img_cur.shape)\n",
    "flow = {'u':u, 'v':v}\n",
    "\n",
    "# sovling aperture problem\n",
    "flow = solving_aperture(flow, corners, grads, window_size=5)\n",
    "\n",
    "# show results\n",
    "img_to_show = cv2.cvtColor((img_next*255).astype('uint8'), cv2.COLOR_GRAY2RGB)\n",
    "csc249.plotFlow(img_to_show, flow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission\n",
    "\n",
    "1. At the menubar, click `Kernel`$\\rightarrow$ `Restart & Run All`\n",
    "2. Download the zip file and upload via blackboard\n",
    "   \n",
    "1% deduction of late assignment total score per hour passing the deadline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csc249\n",
    "csc249.make_submission()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
